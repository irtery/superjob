{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Резюме"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ищем ссылки на резюме с ключевым запросом IT, геолокацией -- Россия (по умолчанию отдается Москва), с поиском ключевого запроса (фильтры) 'по всем словам', 'в тексте резюме', пока не начали постоянно отдаваться дубликаты, ограничения на номер страниц в резюме superjob нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.superjob.ru/resume/3d-modeller-43623349.html\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/resume.csv', index_col=0)\n",
    "old_urls = df.url\n",
    "print(old_urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page: 10 collected: 300\n",
      "page: 20 collected: 600\n",
      "page: 30 collected: 900\n",
      "page: 40 collected: 1200\n",
      "page: 50 collected: 1500\n",
      "page: 60 collected: 1800\n",
      "page: 70 collected: 2100\n",
      "page: 80 collected: 2400\n",
      "page: 90 collected: 2700\n",
      "page: 100 collected: 3000\n",
      "page: 110 collected: 3300\n",
      "page: 120 collected: 3600\n",
      "page: 130 collected: 3900\n",
      "page: 140 collected: 4200\n",
      "page: 150 collected: 4500\n",
      "page: 160 collected: 4800\n",
      "page: 170 collected: 5000\n",
      "page: 180 collected: 5000\n",
      "page: 190 collected: 5000\n",
      "page_count: 198\n"
     ]
    }
   ],
   "source": [
    "main_url = \"https://www.superjob.ru\"\n",
    "search_url = main_url + \"/resume/search_resume.html\"\n",
    "\n",
    "resume_urls = np.array([])\n",
    "all_dublicates_count = 0\n",
    "i = 1\n",
    "while all_dublicates_count < 30:\n",
    "    url_params = {\n",
    "        'c[0]': '1', # это геолокация == Россия\n",
    "        'keywords[0][keys]': 'IT',\n",
    "        'keywords[0][skwc]': 'and',\n",
    "        'keywords[0][srws]': '7',\n",
    "        'page': i\n",
    "    }\n",
    "    resume_html = requests.get(search_url, params=url_params).text\n",
    "    soup = BeautifulSoup(resume_html, 'html.parser')\n",
    "    resume_div = soup.find('div', class_='_1Ttd8 sESpW')\n",
    "    resume_div = resume_div.find_all('div', class_='_3VcZr')[1]\n",
    "    resume_divs = resume_div.find_all('div', class_='_1ruK8')\n",
    "    resume_links = resume_div.find_all('a', class_='icMQ_ f-test-link- _3dPok')\n",
    "    urls = list(map(lambda link: main_url + link.attrs['href'], resume_links))\n",
    "    urls = np.array(urls)\n",
    "    diff = np.unique(np.append(resume_urls, urls)).shape[0] - resume_urls.shape[0] \n",
    "    if diff == 0:\n",
    "        all_dublicates_count += 1\n",
    "    resume_urls = np.unique(np.append(resume_urls, urls))\n",
    "    if (i % 10) == 0:\n",
    "        print(\"page:\", i, \"collected:\", resume_urls.shape[0])\n",
    "    i += 1\n",
    "print(\"page_count:\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "2886\n"
     ]
    }
   ],
   "source": [
    "print(len(resume_urls))\n",
    "new_urls = [i for i in resume_urls if i not in old_urls.values]\n",
    "new_urls = list(new_urls)\n",
    "print(len(new_urls))\n",
    "resume_urls = new_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберу те резюме, у которых указана зарплата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salary(soup):\n",
    "    if not soup:\n",
    "        return\n",
    "    header = list(soup.find('div', class_='_1_bQo _2FJA4').children)\n",
    "    header2 = list(header[1].find('span', class_='_1h3Zg _1fqdH ADNB4').children)[0]\n",
    "    header2 = list(header2)\n",
    "    salary = list(header2[0].find('span', class_='_1h3Zg ADNB4 _1BoTZ').children)[0]\n",
    "    salary = list(salary.children)\n",
    "    if salary[0] == 'По договорённости':\n",
    "        return\n",
    "    return {'salary': salary[0].text + salary[2].text}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категории, в которых лежит резюме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(soup):\n",
    "    category = list(soup.children)[0]\n",
    "    category = soup.find_all('span', class_='_1h3Zg z15vz _1xK5K')[1]\n",
    "    category = [c.text for c in category.find_all('a')]\n",
    "    category.remove('Работа, резюме и вакансии')\n",
    "    category.remove('Резюме')\n",
    "    return {'categories': ', '.join(category)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информация про возраст, пол, город, фото, гражданство и прочее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bio_info(soup):\n",
    "    result = {}\n",
    "    main_info = list(soup.children)[1]\n",
    "    photo = main_info.find('div', class_='jGStW').find('img')\n",
    "    if photo:\n",
    "        result['photo_url'] = 'https:' + photo.attrs['src']\n",
    "    main_info = main_info.find('div', class_='_2XXYS _2cxK3')\n",
    "    main_info = main_info.find_all('div', class_='_2g1F-')\n",
    "    age_gender = list(main_info[0].find('span').children)\n",
    "    age = age_gender[0].find('span').find('span').text\n",
    "    age = re.sub('[\\sа-я]', '', age)\n",
    "    result['age'] = age\n",
    "    gender = age_gender[1].text\n",
    "    if 'женщина' in gender:\n",
    "        result['gender'] = 'f'\n",
    "    elif 'мужчина' in gender:\n",
    "        result['gender'] = 'm'\n",
    "    if len(age_gender) > 2:\n",
    "        result['family'] = re.sub('^, ', '', age_gender[2].text)\n",
    "        if len(age_gender) > 3:\n",
    "            result['family'] += age_gender[3].text\n",
    "    city_moving = list(main_info[1].find('span').children)\n",
    "    if len(city_moving) > 0:\n",
    "        result['city'] = city_moving[0].text\n",
    "        if len(city_moving) > 1:\n",
    "            result['metro_or_moving'] = re.sub(', ', '', city_moving[1].text)\n",
    "    cit = main_info[2].find('span')\n",
    "    if cit:\n",
    "        cit = cit.find('span').text\n",
    "        result['citizenship'] = re.sub('Гражданство: ', '', cit)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информация об опыте работы, образовании и навыках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experience(soup):\n",
    "    result = []\n",
    "    ul = soup.find('ul', class_='_36e54 _2ntFx _1qf3L')\n",
    "    for li in list(ul.children):\n",
    "        exp = {}\n",
    "        div = li.find('div', class_='_9tygw')\n",
    "        periods = list(div.find('ul', class_='_1c9Iy _2XXYS _2cxK3 _1qf3L').children)\n",
    "        exp['period'] = periods[0].find('span').text\n",
    "        exp['length'] = periods[1].find('span', class_='_3AnJT').find('span').text\n",
    "        work_info = list(div.find('div', class_='_3ipSP').children)\n",
    "        title = work_info[0]\n",
    "        exp['name'] = title.find('h3', class_='_1h3Zg ADNB4 _1BoTZ _2SvHc').text\n",
    "        company = title.find('div', class_='_1hd4a')\n",
    "        if company:\n",
    "            exp['company'] = company.find('span').text\n",
    "        duties_ach = list(work_info[1].children)\n",
    "        if len(duties_ach) > 0:\n",
    "            exp['duties'] = duties_ach[0].find('div', class_='_2VtGa _1hd4a').text\n",
    "            exp['duties'] = re.sub('\\n', ' ', exp['duties'])\n",
    "            if len(duties_ach) > 1:\n",
    "                exp['achievments'] = duties_ach[1].find('div', class_='_2VtGa _1hd4a').text\n",
    "                exp['achievments'] = re.sub('\\n', ' ', exp['achievments'])\n",
    "        result.append(exp)\n",
    "    return result\n",
    "\n",
    "def get_education(soup):\n",
    "    result = []\n",
    "    ul = soup.find('ul', class_='_36e54 _2ntFx _1qf3L')\n",
    "    for li in list(ul.children):\n",
    "        ed = {}\n",
    "        div = li.find('div', class_='_9tygw')\n",
    "        periods = list(div.find('ul', class_='_1c9Iy _2XXYS _2cxK3 _1qf3L').children)\n",
    "        ed['kind'] = periods[0].find('div').text\n",
    "        if len(periods) > 1:\n",
    "            text = periods[1].find('div').text\n",
    "            if re.match('^\\d+$', text):\n",
    "                ed['period'] = text\n",
    "            else:\n",
    "                ed['form'] = text\n",
    "            if len(periods) > 2:\n",
    "                ed['period'] = periods[2].find('div').text\n",
    "        info = div.find('div', class_='_7IHu7')\n",
    "        univ = info.find('h3')\n",
    "        if univ:\n",
    "            ed['university'] = univ.text\n",
    "        un_info = info.find('div', class_='NIzpP _2XXYS _2cxK3')\n",
    "        if un_info:\n",
    "            un_info = list(un_info.children)\n",
    "            for ui in un_info:\n",
    "                text = ui.find('div', class_='_1h3Zg z15vz ADNB4 _21a7u _2SvHc').text\n",
    "                if 'Факультет: ' in text:\n",
    "                    ed['faculty'] = re.sub('Факультет: ', '', text)\n",
    "                elif 'Специальность: ' in text:\n",
    "                    ed['specialty'] = re.sub('Специальность: ', '', text)\n",
    "        result.append(ed)\n",
    "    return result\n",
    "\n",
    "def get_languages(soup):\n",
    "    result = []\n",
    "    ul = soup.find('ul', class_='_1_bQo _2FJA4 _1qf3L')\n",
    "    for li in list(ul.children):\n",
    "        result.append(li.find('div').text)\n",
    "    return result\n",
    "\n",
    "def get_skills(soup):\n",
    "    result = []\n",
    "    skills = list(soup.find('div', class_='uI8sE').children)\n",
    "    for skill in skills:\n",
    "        s = {}\n",
    "        name = skill.find('h4').text\n",
    "        if 'Профессиональные навыки:' in name:\n",
    "            s['professional'] = skill.find('div', class_='_2VtGa _1hd4a').text\n",
    "            s['professional'] = re.sub('\\n', ' ', s['professional'])\n",
    "        elif 'Дополнительные сведения:' in name:\n",
    "            s['extra'] = skill.find('div', class_='_2VtGa _1hd4a').text\n",
    "            s['extra'] = re.sub('\\n', ' ', s['extra'])\n",
    "        result.append(s)\n",
    "    return result\n",
    "\n",
    "def get_auto(soup):\n",
    "    result = []\n",
    "    ul = soup.find('ul', class_='_36e54 _2ntFx _1qf3L')\n",
    "    for li in list(ul.children):\n",
    "        result.append(li.find('div').text)\n",
    "    return result\n",
    "\n",
    "def get_work_body_info(soup):\n",
    "    result = {}\n",
    "    body = list(soup.children)\n",
    "    for block in body:\n",
    "        name = block.find('div', class_='riZcC').find('h2').text\n",
    "        if 'Опыт работы' in name:\n",
    "            result['experience_length'] = re.sub('Опыт работы ', '', name)\n",
    "            result['experience'] = get_experience(block)\n",
    "        elif 'Образование' in name:\n",
    "            result['education'] = get_education(block)\n",
    "        elif 'Иностранные языки' in name:\n",
    "            result['languages'] = get_languages(block)\n",
    "        elif 'Знания и навыки' in name:\n",
    "            result['skills'] = get_skills(block)\n",
    "        elif 'Водительские права' in name:\n",
    "            result['auto'] = get_auto(block)\n",
    "    return result\n",
    "\n",
    "def get_work_header_info(soup):\n",
    "    result = {}\n",
    "    header = list(soup.find('div', class_='_1_bQo _2FJA4').children)\n",
    "    result['name'] = header[0].find('h1').text\n",
    "    header2 = list(header[1].find('span', class_='_1h3Zg _1fqdH ADNB4').children)[0]\n",
    "    header2 = list(header2)\n",
    "    if len(header2) > 1:\n",
    "        empl = header2[1].find('span')\n",
    "        if empl:\n",
    "            result['employment'] = empl.text\n",
    "        else:\n",
    "            result['business_trips'] = re.sub('^, ', '', header2[1].text)\n",
    "        if len(header2) > 2:\n",
    "            result['business_trips'] = re.sub('^, ', '', header2[2].text)\n",
    "    return result\n",
    "\n",
    "def get_work_info(soup):\n",
    "    result = {}\n",
    "    info = list(soup.children)[2]\n",
    "    info = list(info.find('div', class_='_1Ttd8 _2CsQi').children)\n",
    "    if len(info) < 3:\n",
    "        return # нам не нужны резюме вида https://www.superjob.ru/resume/direktor-po-it-43971680.html\n",
    "    result.update(get_work_header_info(info[0]))\n",
    "    result.update(get_work_body_info(info[2]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и сбор всего вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url 0 processed, collected 0 resume with salary... url 10 processed, collected 0 resume with salary... url 20 processed, collected 1 resume with salary... url 30 processed, collected 2 resume with salary... url 40 processed, collected 2 resume with salary... url 50 processed, collected 2 resume with salary... url 60 processed, collected 3 resume with salary... url 70 processed, collected 4 resume with salary... url 80 processed, collected 5 resume with salary... url 90 processed, collected 6 resume with salary... url 100 processed, collected 6 resume with salary... url 110 processed, collected 7 resume with salary... url 120 processed, collected 9 resume with salary... url 130 processed, collected 9 resume with salary... url 140 processed, collected 11 resume with salary... url 150 processed, collected 11 resume with salary... url 160 processed, collected 11 resume with salary... url 170 processed, collected 11 resume with salary... url 180 processed, collected 11 resume with salary... url 190 processed, collected 13 resume with salary... url 200 processed, collected 14 resume with salary... url 210 processed, collected 16 resume with salary... url 220 processed, collected 16 resume with salary... url 230 processed, collected 17 resume with salary... url 240 processed, collected 19 resume with salary... url 250 processed, collected 20 resume with salary... url 260 processed, collected 21 resume with salary... url 270 processed, collected 22 resume with salary... url 280 processed, collected 22 resume with salary... url 290 processed, collected 22 resume with salary... url 300 processed, collected 29 resume with salary... url 310 processed, collected 29 resume with salary... url 320 processed, collected 31 resume with salary... url 330 processed, collected 31 resume with salary... url 340 processed, collected 31 resume with salary... url 350 processed, collected 32 resume with salary... url 360 processed, collected 32 resume with salary... url 370 processed, collected 32 resume with salary... url 380 processed, collected 32 resume with salary... url 390 processed, collected 32 resume with salary... url 400 processed, collected 33 resume with salary... url 410 processed, collected 35 resume with salary... url 420 processed, collected 35 resume with salary... url 430 processed, collected 36 resume with salary... url 440 processed, collected 37 resume with salary... url 450 processed, collected 38 resume with salary... url 460 processed, collected 39 resume with salary... url 470 processed, collected 41 resume with salary... url 480 processed, collected 43 resume with salary... url 490 processed, collected 44 resume with salary... url 500 processed, collected 44 resume with salary... url 510 processed, collected 45 resume with salary... url 520 processed, collected 45 resume with salary... url 530 processed, collected 46 resume with salary... url 540 processed, collected 46 resume with salary... url 550 processed, collected 47 resume with salary... url 560 processed, collected 47 resume with salary... url 570 processed, collected 47 resume with salary... url 580 processed, collected 48 resume with salary... url 590 processed, collected 49 resume with salary... url 600 processed, collected 49 resume with salary... url 610 processed, collected 51 resume with salary... url 620 processed, collected 51 resume with salary... url 630 processed, collected 52 resume with salary... url 640 processed, collected 52 resume with salary... url 650 processed, collected 53 resume with salary... url 660 processed, collected 53 resume with salary... url 670 processed, collected 53 resume with salary... url 680 processed, collected 54 resume with salary... url 690 processed, collected 54 resume with salary... url 700 processed, collected 55 resume with salary... url 710 processed, collected 55 resume with salary... url 720 processed, collected 55 resume with salary... url 730 processed, collected 57 resume with salary... url 740 processed, collected 58 resume with salary... url 750 processed, collected 58 resume with salary... url 760 processed, collected 58 resume with salary... url 770 processed, collected 59 resume with salary... url 780 processed, collected 59 resume with salary... url 790 processed, collected 60 resume with salary... url 800 processed, collected 62 resume with salary... url 810 processed, collected 63 resume with salary... url 820 processed, collected 63 resume with salary... url 830 processed, collected 64 resume with salary... url 840 processed, collected 64 resume with salary... url 850 processed, collected 65 resume with salary... url 860 processed, collected 66 resume with salary... url 870 processed, collected 66 resume with salary... url 880 processed, collected 66 resume with salary... url 890 processed, collected 66 resume with salary... url 900 processed, collected 66 resume with salary... url 910 processed, collected 66 resume with salary... url 920 processed, collected 67 resume with salary... url 930 processed, collected 67 resume with salary... url 940 processed, collected 68 resume with salary... url 950 processed, collected 69 resume with salary... url 960 processed, collected 70 resume with salary... url 970 processed, collected 71 resume with salary... url 980 processed, collected 71 resume with salary... url 990 processed, collected 72 resume with salary... url 1000 processed, collected 72 resume with salary... url 1010 processed, collected 72 resume with salary... url 1020 processed, collected 72 resume with salary... url 1030 processed, collected 73 resume with salary... url 1040 processed, collected 73 resume with salary... url 1050 processed, collected 76 resume with salary... url 1060 processed, collected 79 resume with salary... url 1070 processed, collected 85 resume with salary... url 1080 processed, collected 90 resume with salary... url 1090 processed, collected 95 resume with salary... url 1100 processed, collected 96 resume with salary... url 1110 processed, collected 100 resume with salary... url 1120 processed, collected 103 resume with salary... url 1130 processed, collected 103 resume with salary... url 1140 processed, collected 103 resume with salary... url 1150 processed, collected 104 resume with salary... url 1160 processed, collected 104 resume with salary... url 1170 processed, collected 105 resume with salary... url 1180 processed, collected 105 resume with salary... url 1190 processed, collected 106 resume with salary... url 1200 processed, collected 107 resume with salary... url 1210 processed, collected 107 resume with salary... url 1220 processed, collected 110 resume with salary... url 1230 processed, collected 112 resume with salary... url 1240 processed, collected 112 resume with salary... url 1250 processed, collected 113 resume with salary... url 1260 processed, collected 118 resume with salary... url 1270 processed, collected 118 resume with salary... url 1280 processed, collected 118 resume with salary... url 1290 processed, collected 120 resume with salary... url 1300 processed, collected 120 resume with salary... url 1310 processed, collected 121 resume with salary... url 1320 processed, collected 123 resume with salary... url 1330 processed, collected 123 resume with salary... url 1340 processed, collected 123 resume with salary... url 1350 processed, collected 123 resume with salary... url 1360 processed, collected 123 resume with salary... url 1370 processed, collected 124 resume with salary... url 1380 processed, collected 125 resume with salary... url 1390 processed, collected 125 resume with salary... url 1400 processed, collected 126 resume with salary... url 1410 processed, collected 129 resume with salary... url 1420 processed, collected 130 resume with salary... url 1430 processed, collected 130 resume with salary... url 1440 processed, collected 131 resume with salary... url 1450 processed, collected 131 resume with salary... url 1460 processed, collected 132 resume with salary... url 1470 processed, collected 132 resume with salary... url 1480 processed, collected 134 resume with salary... url 1490 processed, collected 134 resume with salary... url 1500 processed, collected 136 resume with salary... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url 1510 processed, collected 136 resume with salary... url 1520 processed, collected 137 resume with salary... url 1530 processed, collected 137 resume with salary... url 1540 processed, collected 138 resume with salary... url 1550 processed, collected 138 resume with salary... url 1560 processed, collected 140 resume with salary... url 1570 processed, collected 141 resume with salary... url 1580 processed, collected 142 resume with salary... url 1590 processed, collected 142 resume with salary... url 1600 processed, collected 143 resume with salary... url 1610 processed, collected 143 resume with salary... url 1620 processed, collected 143 resume with salary... url 1630 processed, collected 145 resume with salary... url 1640 processed, collected 148 resume with salary... url 1650 processed, collected 149 resume with salary... url 1660 processed, collected 149 resume with salary... url 1670 processed, collected 150 resume with salary... url 1680 processed, collected 150 resume with salary... url 1690 processed, collected 151 resume with salary... url 1700 processed, collected 152 resume with salary... url 1710 processed, collected 153 resume with salary... url 1720 processed, collected 153 resume with salary... url 1730 processed, collected 153 resume with salary... url 1740 processed, collected 155 resume with salary... url 1750 processed, collected 156 resume with salary... url 1760 processed, collected 157 resume with salary... url 1770 processed, collected 157 resume with salary... url 1780 processed, collected 158 resume with salary... url 1790 processed, collected 158 resume with salary... url 1800 processed, collected 158 resume with salary... url 1810 processed, collected 158 resume with salary... url 1820 processed, collected 159 resume with salary... url 1830 processed, collected 159 resume with salary... url 1840 processed, collected 160 resume with salary... url 1850 processed, collected 160 resume with salary... url 1860 processed, collected 163 resume with salary... url 1870 processed, collected 164 resume with salary... url 1880 processed, collected 167 resume with salary... url 1890 processed, collected 168 resume with salary... url 1900 processed, collected 169 resume with salary... url 1910 processed, collected 171 resume with salary... url 1920 processed, collected 173 resume with salary... url 1930 processed, collected 173 resume with salary... url 1940 processed, collected 175 resume with salary... url 1950 processed, collected 176 resume with salary... url 1960 processed, collected 176 resume with salary... url 1970 processed, collected 176 resume with salary... url 1980 processed, collected 177 resume with salary... url 1990 processed, collected 177 resume with salary... url 2000 processed, collected 177 resume with salary... url 2010 processed, collected 177 resume with salary... url 2020 processed, collected 177 resume with salary... url 2030 processed, collected 177 resume with salary... url 2040 processed, collected 179 resume with salary... url 2050 processed, collected 179 resume with salary... url 2060 processed, collected 179 resume with salary... url 2070 processed, collected 180 resume with salary... url 2080 processed, collected 181 resume with salary... url 2090 processed, collected 182 resume with salary... url 2100 processed, collected 183 resume with salary... url 2110 processed, collected 183 resume with salary... url 2120 processed, collected 184 resume with salary... url 2130 processed, collected 185 resume with salary... url 2140 processed, collected 186 resume with salary... url 2150 processed, collected 187 resume with salary... url 2160 processed, collected 188 resume with salary... url 2170 processed, collected 189 resume with salary... url 2180 processed, collected 189 resume with salary... url 2190 processed, collected 189 resume with salary... url 2200 processed, collected 189 resume with salary... url 2210 processed, collected 190 resume with salary... url 2220 processed, collected 190 resume with salary... url 2230 processed, collected 191 resume with salary... url 2240 processed, collected 192 resume with salary... url 2250 processed, collected 192 resume with salary... url 2260 processed, collected 192 resume with salary... url 2270 processed, collected 193 resume with salary... url 2280 processed, collected 193 resume with salary... url 2290 processed, collected 194 resume with salary... url 2300 processed, collected 194 resume with salary... url 2310 processed, collected 194 resume with salary... url 2320 processed, collected 195 resume with salary... url 2330 processed, collected 196 resume with salary... url 2340 processed, collected 196 resume with salary... url 2350 processed, collected 196 resume with salary... url 2360 processed, collected 196 resume with salary... url 2370 processed, collected 196 resume with salary... url 2380 processed, collected 197 resume with salary... url 2390 processed, collected 197 resume with salary... url 2400 processed, collected 198 resume with salary... url 2410 processed, collected 199 resume with salary... url 2420 processed, collected 201 resume with salary... url 2430 processed, collected 202 resume with salary... url 2440 processed, collected 204 resume with salary... url 2450 processed, collected 206 resume with salary... url 2460 processed, collected 211 resume with salary... url 2470 processed, collected 216 resume with salary... url 2480 processed, collected 217 resume with salary... url 2490 processed, collected 222 resume with salary... url 2500 processed, collected 224 resume with salary... url 2510 processed, collected 227 resume with salary... url 2520 processed, collected 227 resume with salary... url 2530 processed, collected 228 resume with salary... url 2540 processed, collected 231 resume with salary... url 2550 processed, collected 232 resume with salary... url 2560 processed, collected 235 resume with salary... url 2570 processed, collected 235 resume with salary... url 2580 processed, collected 237 resume with salary... url 2590 processed, collected 237 resume with salary... url 2600 processed, collected 237 resume with salary... url 2610 processed, collected 238 resume with salary... url 2620 processed, collected 239 resume with salary... url 2630 processed, collected 243 resume with salary... url 2640 processed, collected 243 resume with salary... url 2650 processed, collected 244 resume with salary... url 2660 processed, collected 245 resume with salary... url 2670 processed, collected 247 resume with salary... url 2680 processed, collected 247 resume with salary... url 2690 processed, collected 247 resume with salary... url 2700 processed, collected 248 resume with salary... url 2710 processed, collected 249 resume with salary... url 2720 processed, collected 251 resume with salary... url 2730 processed, collected 253 resume with salary... url 2740 processed, collected 255 resume with salary... url 2750 processed, collected 256 resume with salary... url 2760 processed, collected 258 resume with salary... url 2770 processed, collected 258 resume with salary... url 2780 processed, collected 259 resume with salary... url 2790 processed, collected 259 resume with salary... url 2800 processed, collected 261 resume with salary... url 2810 processed, collected 261 resume with salary... url 2820 processed, collected 261 resume with salary... url 2830 processed, collected 262 resume with salary... url 2840 processed, collected 263 resume with salary... url 2850 processed, collected 263 resume with salary... url 2860 processed, collected 264 resume with salary... url 2870 processed, collected 265 resume with salary... url 2880 processed, collected 266 resume with salary... "
     ]
    }
   ],
   "source": [
    "def collect_resume(soup):\n",
    "    result = {}\n",
    "    salary = get_salary(soup)\n",
    "    if not salary:\n",
    "        return\n",
    "    result.update(salary)\n",
    "    result.update(get_categories(soup))\n",
    "    result.update(get_bio_info(soup))\n",
    "    work_info = get_work_info(soup)\n",
    "    if not work_info:\n",
    "        return\n",
    "    result.update(work_info)\n",
    "    return result\n",
    "\n",
    "result = []\n",
    "for url_id, url in enumerate(resume_urls):\n",
    "    resume_html = requests.get(url).text\n",
    "    resume_html = resume_html.replace('\\xa0',' ')\n",
    "    soup = BeautifulSoup(resume_html, 'html.parser')\n",
    "    soup = soup.find('div', class_='_1x409')\n",
    "    soup = soup.find('div', class_='_36e54 _2ntFx')\n",
    "    try:\n",
    "        resume = collect_resume(soup)\n",
    "        if resume:\n",
    "            resume['url'] = url\n",
    "            result.append(resume)\n",
    "    except:\n",
    "        print(url_id, url)\n",
    "    if (url_id % 10) == 0:\n",
    "         print(\"url\", url_id, \"processed, collected\", len(result), 'resume with salary...', end=' ')\n",
    "\n",
    "#check some url\n",
    "# url = resume_urls[14]\n",
    "# print(url)\n",
    "# resume_html = requests.get(url).text\n",
    "# resume_html = resume_html.replace('\\xa0',' ')\n",
    "# soup = BeautifulSoup(resume_html, 'html.parser')\n",
    "# soup = soup.find('div', class_='_1x409')\n",
    "# soup = soup.find('div', class_='_36e54 _2ntFx')\n",
    "# resume = collect_resume(soup)\n",
    "# if resume:\n",
    "#     resume['url'] = url\n",
    "#     for k, v in resume.items():\n",
    "#         print(''*10)\n",
    "#         print(k, \":\", v)\n",
    "#     result.append(resume)\n",
    "# else:\n",
    "#     print('no salary datermined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось резюме с указанной зарплатой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>auto</th>\n",
       "      <th>business_trips</th>\n",
       "      <th>categories</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>city</th>\n",
       "      <th>education</th>\n",
       "      <th>employment</th>\n",
       "      <th>experience</th>\n",
       "      <th>experience_length</th>\n",
       "      <th>family</th>\n",
       "      <th>gender</th>\n",
       "      <th>languages</th>\n",
       "      <th>metro_or_moving</th>\n",
       "      <th>name</th>\n",
       "      <th>photo_url</th>\n",
       "      <th>salary</th>\n",
       "      <th>skills</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Внедрение и сопровождение ПО</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Краснодар</td>\n",
       "      <td>[{'kind': 'Высшее образование', 'form': 'Дневн...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'period': 'апрель 2014 – работает сейчас', '...</td>\n",
       "      <td>9 лет и 2 месяца</td>\n",
       "      <td>не состоит в браке, детей нет</td>\n",
       "      <td>f</td>\n",
       "      <td>[Английский язык, Базовый]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Аналитик, специалист по внедрению проектов IT,...</td>\n",
       "      <td>https://public.superjob.ru/images/resume_fotos...</td>\n",
       "      <td>36 000₽</td>\n",
       "      <td>[{'professional': 'Microsoft Office, SQL, Dedu...</td>\n",
       "      <td>https://www.superjob.ru/resume/analitik-442003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>[B — легковые авто]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Экономический анализ</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Уфа</td>\n",
       "      <td>[{'kind': 'Высшее образование', 'form': 'Дневн...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'period': 'январь 2010 – октябрь 2018', 'len...</td>\n",
       "      <td>14 лет и 4 месяца</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>[Английский язык, Базовый, Немецкий язык, Базо...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Аналитик по продажам, Логист, Снабженец, IT-сп...</td>\n",
       "      <td>https://public.superjob.ru/images/resume_fotos...</td>\n",
       "      <td>35 000₽</td>\n",
       "      <td>[{'professional': 'Компьютерные (1С, Супермаг,...</td>\n",
       "      <td>https://www.superjob.ru/resume/analitik-po-pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>[B — легковые авто]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Административная работа, секретариат, АХО</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Москва</td>\n",
       "      <td>[{'kind': 'Высшее образование', 'form': 'Дневн...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'period': 'июнь 2010 – июнь 2018', 'length':...</td>\n",
       "      <td>22 года и 9 месяцев</td>\n",
       "      <td>cостоит в браке, есть дети</td>\n",
       "      <td>m</td>\n",
       "      <td>[Английский язык, Cвободное владение]</td>\n",
       "      <td>готов к переезду</td>\n",
       "      <td>CIO / Head of IT / IT Manager</td>\n",
       "      <td>https://public.superjob.ru/images/resume_fotos...</td>\n",
       "      <td>200 000₽</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.superjob.ru/resume/cio-44065482.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>[B — легковые авто, C — грузовые авто]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Электронный документооборот</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Тверь</td>\n",
       "      <td>[{'kind': 'Высшее образование', 'form': 'Дневн...</td>\n",
       "      <td>полная занятость</td>\n",
       "      <td>[{'period': 'август 2015 – июнь 2016', 'length...</td>\n",
       "      <td>25 лет и 7 месяцев</td>\n",
       "      <td>не состоит в браке, детей нет</td>\n",
       "      <td>m</td>\n",
       "      <td>[Английский язык, Технический, Немецкий язык, ...</td>\n",
       "      <td>готов к переезду</td>\n",
       "      <td>Директор, заместитель директора, руководителя,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45 000₽</td>\n",
       "      <td>[{'professional': 'Хорошие организаторские спо...</td>\n",
       "      <td>https://www.superjob.ru/resume/direktor-266630...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>[B — легковые авто]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Сетевые технологии</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Оренбург</td>\n",
       "      <td>[{'kind': 'Высшее образование', 'form': 'Заочн...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'period': 'июнь 2007 – работает сейчас', 'le...</td>\n",
       "      <td>15 лет и 8 месяцев</td>\n",
       "      <td>cостоит в браке, есть дети</td>\n",
       "      <td>m</td>\n",
       "      <td>[Английский язык, Базовый]</td>\n",
       "      <td>готов к переезду</td>\n",
       "      <td>Директор ИТ, Технический директор, Руководител...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25 000₽</td>\n",
       "      <td>[{'professional': '1. Опыт организаторской раб...</td>\n",
       "      <td>https://www.superjob.ru/resume/direktor-it-206...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age                                    auto business_trips  \\\n",
       "0  29                                     NaN            NaN   \n",
       "1  40                     [B — легковые авто]            NaN   \n",
       "2  40                     [B — легковые авто]            NaN   \n",
       "3  50  [B — легковые авто, C — грузовые авто]            NaN   \n",
       "4  35                     [B — легковые авто]            NaN   \n",
       "\n",
       "                                  categories citizenship       city  \\\n",
       "0               Внедрение и сопровождение ПО      Россия  Краснодар   \n",
       "1                       Экономический анализ      Россия        Уфа   \n",
       "2  Административная работа, секретариат, АХО      Россия     Москва   \n",
       "3                Электронный документооборот      Россия      Тверь   \n",
       "4                         Сетевые технологии         NaN   Оренбург   \n",
       "\n",
       "                                           education        employment  \\\n",
       "0  [{'kind': 'Высшее образование', 'form': 'Дневн...               NaN   \n",
       "1  [{'kind': 'Высшее образование', 'form': 'Дневн...               NaN   \n",
       "2  [{'kind': 'Высшее образование', 'form': 'Дневн...               NaN   \n",
       "3  [{'kind': 'Высшее образование', 'form': 'Дневн...  полная занятость   \n",
       "4  [{'kind': 'Высшее образование', 'form': 'Заочн...               NaN   \n",
       "\n",
       "                                          experience    experience_length  \\\n",
       "0  [{'period': 'апрель 2014 – работает сейчас', '...     9 лет и 2 месяца   \n",
       "1  [{'period': 'январь 2010 – октябрь 2018', 'len...    14 лет и 4 месяца   \n",
       "2  [{'period': 'июнь 2010 – июнь 2018', 'length':...  22 года и 9 месяцев   \n",
       "3  [{'period': 'август 2015 – июнь 2016', 'length...   25 лет и 7 месяцев   \n",
       "4  [{'period': 'июнь 2007 – работает сейчас', 'le...   15 лет и 8 месяцев   \n",
       "\n",
       "                          family gender  \\\n",
       "0  не состоит в браке, детей нет      f   \n",
       "1                            NaN      m   \n",
       "2     cостоит в браке, есть дети      m   \n",
       "3  не состоит в браке, детей нет      m   \n",
       "4     cостоит в браке, есть дети      m   \n",
       "\n",
       "                                           languages   metro_or_moving  \\\n",
       "0                         [Английский язык, Базовый]               NaN   \n",
       "1  [Английский язык, Базовый, Немецкий язык, Базо...               NaN   \n",
       "2              [Английский язык, Cвободное владение]  готов к переезду   \n",
       "3  [Английский язык, Технический, Немецкий язык, ...  готов к переезду   \n",
       "4                         [Английский язык, Базовый]  готов к переезду   \n",
       "\n",
       "                                                name  \\\n",
       "0  Аналитик, специалист по внедрению проектов IT,...   \n",
       "1  Аналитик по продажам, Логист, Снабженец, IT-сп...   \n",
       "2                      CIO / Head of IT / IT Manager   \n",
       "3  Директор, заместитель директора, руководителя,...   \n",
       "4  Директор ИТ, Технический директор, Руководител...   \n",
       "\n",
       "                                           photo_url    salary  \\\n",
       "0  https://public.superjob.ru/images/resume_fotos...   36 000₽   \n",
       "1  https://public.superjob.ru/images/resume_fotos...   35 000₽   \n",
       "2  https://public.superjob.ru/images/resume_fotos...  200 000₽   \n",
       "3                                                NaN   45 000₽   \n",
       "4                                                NaN   25 000₽   \n",
       "\n",
       "                                              skills  \\\n",
       "0  [{'professional': 'Microsoft Office, SQL, Dedu...   \n",
       "1  [{'professional': 'Компьютерные (1С, Супермаг,...   \n",
       "2                                                NaN   \n",
       "3  [{'professional': 'Хорошие организаторские спо...   \n",
       "4  [{'professional': '1. Опыт организаторской раб...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.superjob.ru/resume/analitik-442003...  \n",
       "1  https://www.superjob.ru/resume/analitik-po-pro...  \n",
       "2   https://www.superjob.ru/resume/cio-44065482.html  \n",
       "3  https://www.superjob.ru/resume/direktor-266630...  \n",
       "4  https://www.superjob.ru/resume/direktor-it-206...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# и сохранение\n",
    "df = pd.DataFrame(result)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/new_resume.csv', mode='w', encoding='utf-8') as f_csv:\n",
    "    df.to_csv(f_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
